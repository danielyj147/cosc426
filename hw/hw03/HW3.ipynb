{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd91e7f3-3db3-465f-8437-5c604d3f2494",
   "metadata": {},
   "source": [
    "## HW 3: Evaluating language models \n",
    "### COSC 426: Fall 2025, Colgate University\n",
    "\n",
    "Use this notebook to run your experiments for Part 1, load and display from your experiment from Part 2, and answer the questions in all parts. Feel free to add as many code and markdown chunks as you would like in each of the sub-sections. \n",
    "\n",
    "**If you use any external resources (e.g., code snippets, reference articles), please cite them in comments or text!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96443a87-57c4-4c18-a825-9e9aa8cd0f32",
   "metadata": {},
   "source": [
    "## Part 1: Train and evaluate bigram and trigram models \n",
    "\n",
    "In this section, include the experiments to train and evaluate bigram and trigram models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18832e8d-7d6f-4f41-b0f4-66774c1b693e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grushaprasad/opt/anaconda3/envs/cosc410/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259f82b-a926-43f3-9692-767130347103",
   "metadata": {},
   "source": [
    "## Part 2: Train and evaluate `distilgpt2` model\n",
    "\n",
    "In this part, load in the results from your trained `distilgpt2` model from NLPScholar, and evaluate the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3e5180-baba-4983-9614-8699a17b2deb",
   "metadata": {},
   "source": [
    "## Part 3: Reflect on the role of tokenizer\n",
    "In this part, answer the question in `HW3.md` in markdown chunks. If you used external sources to find and make sense of this, please cite them!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524849f-ba17-450e-88d6-2927644d0130",
   "metadata": {},
   "source": [
    "## Part 4 (Optional): Explore the effect of tokenizer and vocab on ngram model performance\n",
    "\n",
    "In this part, include the results from your experiments (if you choose to attempt this)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosc410",
   "language": "python",
   "name": "cosc410"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
