{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd94d006-85a8-4c99-86dc-75f81f2b5b88",
   "metadata": {},
   "source": [
    "# HW 4: Text Classification\n",
    "### COSC 426: Fall 2025, Colgate University\n",
    "\n",
    "Use this notebook to answer questions and load + display from your experiments. Feel free to add as many code and markdown chunks as you would like in each of the sub-sections. \n",
    "\n",
    "**If you use any external resources (e.g., code snippets, reference articles), please cite them in comments or text!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b9e1d-646a-49c2-8e2e-62b6c194d830",
   "metadata": {},
   "source": [
    "## Part 1: Train and evaluate `distilgpt` based Bayesian Classifier\n",
    "\n",
    "In this part, load in the probability estimates from your finetuned **language models**, use it to classify text, and display classification results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8bd4fb",
   "metadata": {},
   "source": [
    "We want to calculate the probability of text given its class(likelihood), so we want to finetune two separate models, one trained on only the positive sentiment text, and the other trained on only the negative sentiment text. \n",
    "\n",
    "For the train configuration, we will use minimal pair comparison mode with `loadPretrained` set to `true`(or not specified since it is true by default) since we want to finetune the distilgpt model. \n",
    "\n",
    "The training/validation data split will be 8:2.\n",
    "Also, since we want to train 2 separate models, we will have 2 diffrent pairs of train-val datasets one with positive reviews and another with negative reviews. \n",
    "\n",
    "The preprocessed training/validation data will be in the format of \n",
    "\n",
    "| text |\n",
    "| :-------: |\n",
    "| `review` |\n",
    "| ... |\n",
    "\n",
    "Since we want to calcualte the probability of text given class, \n",
    "we need to evaluate positive and negative reviews separately, each evaluated by corresponding model(negative review with negative review model and vice versa).\n",
    "So we need to separate the `test` set into `positive_test` and `negative_test` sets and run the evaluation separately. \n",
    "\n",
    "| sentid | pairid | comparison | sentence |\n",
    "| :-------: | :------: | :-------: | :-------: | \n",
    "| 0 | 0 | expected | `review` |\n",
    "| 0 | 0 | expected | `review` |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "Finally, we can load the results & aggreate the accuracy of the model to get the combined model's likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fae9b",
   "metadata": {},
   "source": [
    "### Train & Val Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c9e19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "nf = \"./aclImdb/train/neg\"\n",
    "ntfs = [f\"{nf}/{path}\" for path in os.listdir(nf)[:2500]]  # negative train files\n",
    "nvfs = [f\"{nf}/{path}\" for path in os.listdir(nf)[2500:3000]]  # negative val files\n",
    "\n",
    "pf = \"./aclImdb/train/pos\"\n",
    "ptfs = [f\"{pf}/{path}\" for path in os.listdir(pf)[:2500]]  # positive train files\n",
    "pvfs = [f\"{pf}/{path}\" for path in os.listdir(pf)[2500:3000]]  # positive val files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c103896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def txts2tsv(paths: list[str], savefpath: str) -> None:\n",
    "    \"\"\"Generates a tsv file consisted of the frist line of each file\n",
    "\n",
    "    Args:\n",
    "        paths (list[str]): paths of source files\n",
    "        savefpath (str): save path\n",
    "    \"\"\"\n",
    "    rows = [['text']]\n",
    "    for path in paths:\n",
    "        with open(path, 'r') as f:\n",
    "            rows.append([f.readline()])\n",
    "\n",
    "    with open(savefpath, \"w\", newline=\"\") as f:\n",
    "        fw = csv.writer(f)\n",
    "        fw.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86e0fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {\n",
    "    'data/neg_train.tsv': ntfs,\n",
    "    'data/neg_val.tsv': nvfs,\n",
    "    'data/pos_train.tsv': ptfs,\n",
    "    'data/pos_val.tsv': pvfs\n",
    "    }\n",
    "\n",
    "for savefpath, paths in t.items():\n",
    "    txts2tsv(paths, savefpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7e7af",
   "metadata": {},
   "source": [
    "### Eval Dataset Genration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6800ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "nef = \"./aclImdb/test/neg\"\n",
    "nefs = [f\"{nef}/{path}\" for path in os.listdir(nef)[:1000]]  # negative eval files\n",
    "\n",
    "pef = \"./aclImdb/test/pos\"\n",
    "pefs = [f\"{pef}/{path}\" for path in os.listdir(pef)[:1000]]  # positive eval files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "350e14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = {\n",
    "    'data/neg_eval.tsv': nefs,\n",
    "    'data/pos_eval.tsv': pefs\n",
    "    }\n",
    "\n",
    "for savefpath, paths in e.items():\n",
    "    rows = [['sentid', 'pairid', 'comparison', 'sentence']]\n",
    "    for path in paths:    \n",
    "        with open(path, 'r') as f:\n",
    "            rows.append([0, 0, 'expected', f.readline()])\n",
    "    \n",
    "    with open(savefpath, 'w') as f:\n",
    "        fw = csv.writer(f, delimiter='\\t')\n",
    "        fw.writerows(rows)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f83bbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "ndf = pd.read_csv('predictions/neg_predictions.tsv', sep='\\t')\n",
    "pdf = pd.read_csv('predictions/pos_predictions.tsv', sep='\\t')\n",
    "df = pd.concat([ndf, pdf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2944c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x11286a5d0>,\n",
       "  <matplotlib.lines.Line2D at 0x11286a710>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x11286a850>,\n",
       "  <matplotlib.lines.Line2D at 0x11286a990>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1127a2350>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x11286aad0>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1127a3d90>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(df['prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "814f4dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Overall Likeliehood: 0.209\n",
      "Assumed Prior: 0.5\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 40)\n",
    "likelihood = df['prob'].mean()\n",
    "print(f\"Overall Likeliehood: {likelihood:.3f}\")\n",
    "\n",
    "prior = 1/len(['pos', 'neg'])\n",
    "print(f\"Assumed Prior: {prior:.1f}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f3c6e",
   "metadata": {},
   "source": [
    "In general, p(class|text) ∝ likelihood * prior. However, since we assume uniform prior, it does not affect the proportionality, and the likelihood becomes the only factor that affects the result. The likelihood of 0.21 is good since if the model knew nothing and simply guessed the next word ranomly, the probability of getting it correct is 1/vocab-size which would be fairly small. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64288a30-d61e-4286-a12f-3ed8a5d50733",
   "metadata": {},
   "source": [
    "## Part 2: Train and evaluate a `distilgpt` based TextClassification model\n",
    "In this part, load in and display the results from your finetuned **TextClassification models**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24723c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fafec7b6-883b-47bd-8e51-2fc6ad8453fe",
   "metadata": {},
   "source": [
    "## Part 3: Reflect on the two approaches to classification\n",
    "\n",
    "In this part, answer the question in `HW4.md` in markdown chunks. If you used external sources to find and make sense of this, please cite them!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888814d-3dd3-4cf1-b109-c7b2676b7691",
   "metadata": {},
   "source": [
    "## Part 4 (Optional): Error analysis comparing the two approaches to classification\n",
    "\n",
    "In this part, include the results from your experiments (if you choose to attempt this)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
