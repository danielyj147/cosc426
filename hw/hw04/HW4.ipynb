{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd94d006-85a8-4c99-86dc-75f81f2b5b88",
   "metadata": {},
   "source": [
    "# HW 4: Text Classification\n",
    "### COSC 426: Fall 2025, Colgate University\n",
    "\n",
    "Use this notebook to answer questions and load + display from your experiments. Feel free to add as many code and markdown chunks as you would like in each of the sub-sections. \n",
    "\n",
    "**If you use any external resources (e.g., code snippets, reference articles), please cite them in comments or text!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b9e1d-646a-49c2-8e2e-62b6c194d830",
   "metadata": {},
   "source": [
    "## Part 1: Train and evaluate `distilgpt` based Bayesian Classifier\n",
    "\n",
    "In this part, load in the probability estimates from your finetuned **language models**, use it to classify text, and display classification results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8bd4fb",
   "metadata": {},
   "source": [
    "We want to calculate the probability of text given its class(likelihood), so we want to finetune two separate models, one trained on only the positive sentiment text, and the other trained on only the negative sentiment text. \n",
    "\n",
    "For the train configuration, we will use minimal pair comparison mode with `loadPretrained` set to `true`(or not specified since it is true by default) since we want to finetune the distilgpt model. \n",
    "\n",
    "The training/validation data split will be 8:2.\n",
    "Also, since we want to train 2 separate models, we will have 2 diffrent pairs of train-val datasets one with positive reviews and another with negative reviews. \n",
    "\n",
    "The preprocessed training/validation data will be in the format of \n",
    "\n",
    "| text |\n",
    "| :-------: |\n",
    "| `review` |\n",
    "| ... |\n",
    "\n",
    "Since we want to calcualte the probability of text given class, \n",
    "we need to evaluate positive and negative reviews separately, each evaluated by corresponding model(negative review with negative review model and vice versa).\n",
    "So we need to separate the `test` set into `positive_test` and `negative_test` sets and run the evaluation separately. \n",
    "\n",
    "| sentid | pairid | comparison | sentence |\n",
    "| :-------: | :------: | :-------: | :-------: | \n",
    "| 0 | 0 | expected | `review` |\n",
    "| 0 | 0 | expected | `review` |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "Finally, we can load the results & aggreate the accuracy of the model to get the combined model's likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fae9b",
   "metadata": {},
   "source": [
    "### Train & Val Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c9e19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "nf = \"./aclImdb/train/neg\"\n",
    "ntfs = [f\"{nf}/{path}\" for path in os.listdir(nf)[:2500]]  # negative train files\n",
    "nvfs = [f\"{nf}/{path}\" for path in os.listdir(nf)[2500:3000]]  # negative val files\n",
    "\n",
    "pf = \"./aclImdb/train/pos\"\n",
    "ptfs = [f\"{pf}/{path}\" for path in os.listdir(pf)[:2500]]  # positive train files\n",
    "pvfs = [f\"{pf}/{path}\" for path in os.listdir(pf)[2500:3000]]  # positive val files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c103896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def txts2tsv(paths: list[str], savefpath: str) -> None:\n",
    "    \"\"\"Generates a tsv file consisted of the frist line of each file\n",
    "\n",
    "    Args:\n",
    "        paths (list[str]): paths of source files\n",
    "        savefpath (str): save path\n",
    "    \"\"\"\n",
    "    rows = [['text']]\n",
    "    for path in paths:\n",
    "        with open(path, 'r') as f:\n",
    "            rows.append([f.readline()])\n",
    "\n",
    "    with open(savefpath, \"w\", newline=\"\") as f:\n",
    "        fw = csv.writer(f)\n",
    "        fw.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e0fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {\n",
    "    'data/neg_train.tsv': ntfs,\n",
    "    'data/neg_val.tsv': nvfs,\n",
    "    'data/pos_train.tsv': ptfs,\n",
    "    'data/pos_val.tsv': pvfs\n",
    "    }\n",
    "\n",
    "for savefpath, paths in t.items():\n",
    "    txts2tsv(paths, savefpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7e7af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64288a30-d61e-4286-a12f-3ed8a5d50733",
   "metadata": {},
   "source": [
    "## Part 2: Train and evaluate a `distilgpt` based TextClassification model\n",
    "In this part, load in and display the results from your finetuned **TextClassification models**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafec7b6-883b-47bd-8e51-2fc6ad8453fe",
   "metadata": {},
   "source": [
    "## Part 3: Reflect on the two approaches to classification\n",
    "\n",
    "In this part, answer the question in `HW4.md` in markdown chunks. If you used external sources to find and make sense of this, please cite them!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888814d-3dd3-4cf1-b109-c7b2676b7691",
   "metadata": {},
   "source": [
    "## Part 4 (Optional): Error analysis comparing the two approaches to classification\n",
    "\n",
    "In this part, include the results from your experiments (if you choose to attempt this)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
