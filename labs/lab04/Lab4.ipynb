{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f397c0dc-1fed-4f5b-89a8-e0af21e06c0a",
   "metadata": {},
   "source": [
    "# Lab 3: Grammar writing\n",
    "### COSC 426: Fall 2025, Colgate University\n",
    "\n",
    "Use this notebook to answer the questions in `Lab4.md`. Make sure to include in this notebook all the tests you run to ensure that at each stage your n-gram model implementation is correct. Please use **markdown** chunks to answer any non-code questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbda0e4a-6302-4d4e-8c55-cc75a8648a0c",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "Answer questions for each of the subparts here. Add as many markdown chunks as needed under each sub-part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef565601-0982-4932-a12d-290e1dd28b60",
   "metadata": {},
   "source": [
    "### Part 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83231c5d",
   "metadata": {},
   "source": [
    "text = ['the panda eats the sandwich in her pajamas',\n",
    "         'a sandwich likes a panda',\n",
    "         'the sandwich likes her panda in some pajamas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172b06a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 3, 'panda': 3, 'eats': 1, 'sandwich': 3, 'in': 2, 'her': 2, 'pajamas': 2, 'a': 2, 'likes': 2, 'some': 1}\n"
     ]
    }
   ],
   "source": [
    "text = ['the panda eats the sandwich in her pajamas',\n",
    "         'a sandwich likes a panda',\n",
    "         'the sandwich likes her panda in some pajamas']\n",
    "# find the wordcount for each word in the text\n",
    "wordcount = {}\n",
    "for line in text:\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        if word in wordcount:\n",
    "            wordcount[word] += 1\n",
    "        else:\n",
    "            wordcount[word] = 1\n",
    "print(wordcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd82c0",
   "metadata": {},
   "source": [
    "p(the, panda) = count(the panda) / count(the) = 1/3 = .33\n",
    "\n",
    "p(a, sandwich) = count(a sandwich) / count(a) = 1/2\n",
    "\n",
    "p(in, the) = count(in the) / count(in) = 0/2 = 0\n",
    "\n",
    "p(panda, eats) = count(panda eats) / count(panda) = 1 / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea82ca-2c1a-437a-824e-4620c4449a5b",
   "metadata": {},
   "source": [
    "### Part 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d797b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['the panda eats the sandwich in her pajamas',\n",
    "         'a sandwich likes a panda',\n",
    "         'the sandwich likes her panda in some pajamas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc2d2c",
   "metadata": {},
   "source": [
    "([BOS], the) = 2/3\n",
    "([UNK], panda) = 1/5\n",
    "(likes, [UNK]) = 1/2 // her, pamajas, some\n",
    "([UNK], peacefully) = 0/5\n",
    "([UNK], [UNK]) = 2 / 5 // her pajamas, some pajamas\n",
    "(panda, [EOS]) = 1 / 3\n",
    "(likes, sandwich) = 0 / 2\n",
    "\n",
    "1. It give additional context in a bigram model. using these tokens expresses probabilities of words occuring at the beginning and the end of the sentnece. This eliminates unlikely bigrams across the end of a sentence from owhterwise occuring. \n",
    "2. The UNK "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6fd57d-96f3-4c25-ab34-eabcbb64bc2a",
   "metadata": {},
   "source": [
    "### Part 1.3\n",
    "|V| = 13\n",
    "k = 1\n",
    "\n",
    "text = ['the panda eats the sandwich in her pajamas',\n",
    "         'a sandwich likes a panda',\n",
    "         'the sandwich likes her panda in some pajamas']\n",
    "\n",
    "(the, panda) = (1+1)/(3+13*1) = .125  \n",
    "\n",
    "(a, sandwich) = (1+1)/(3+13*1) = 2/15\n",
    "\n",
    "(in, the) = 1/15\n",
    "\n",
    "(panda, eats) = 2/16 \n",
    "\n",
    "([BOS], the) = 3/16  \n",
    "([UNK], [UNK]) = 3/18 = 1/6  \n",
    "(panda, [EOS]) = 2/16 1/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00491d7c-b24b-424a-a314-72add06b1283",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Use this part to test your code. Feel free to add any additional code chunks. Note, once you make changes to `Lab4.py` you might have to restart the kernel for the changes to be reflected here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41733e9b-9e0e-42ef-a958-39dd5600f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    TestBigramFreqs(getBigramFreqs(preprocess('data/test.txt', mark_ends=True), getVocab('data/glove_vocab.txt')))\n",
      "Expecting:\n",
      "    {1: 70, 2: 3}\n",
      "**********************************************************************\n",
      "File \"/Users/jeong/Projects/cosc426-projects/cosc426/labs/lab04/Lab4.py\", line 91, in Lab4.getBigramFreqs\n",
      "Failed example:\n",
      "    TestBigramFreqs(getBigramFreqs(preprocess('data/test.txt', mark_ends=True), getVocab('data/glove_vocab.txt')))\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"/Users/jeong/miniconda3/envs/nlp/lib/python3.10/doctest.py\", line 1350, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest Lab4.getBigramFreqs[0]>\", line 1, in <module>\n",
      "        TestBigramFreqs(getBigramFreqs(preprocess('data/test.txt', mark_ends=True), getVocab('data/glove_vocab.txt')))\n",
      "      File \"/Users/jeong/Projects/cosc426-projects/cosc426/labs/lab04/Lab4.py\", line 100, in getBigramFreqs\n",
      "        words = line.split()\n",
      "    AttributeError: 'list' object has no attribute 'split'\n",
      "Trying:\n",
      "    TestBigramFreqs(getBigramFreqs(preprocess('data/test.txt', mark_ends=True), getVocab('data/glove_vocab.txt')), print_non1=True)\n",
      "Expecting:\n",
      "    {2: [('kitten', 'had'), ('.', '[EOS]'), ('for', 'the')]}\n",
      "**********************************************************************\n",
      "File \"/Users/jeong/Projects/cosc426-projects/cosc426/labs/lab04/Lab4.py\", line 94, in Lab4.getBigramFreqs\n",
      "Failed example:\n",
      "    TestBigramFreqs(getBigramFreqs(preprocess('data/test.txt', mark_ends=True), getVocab('data/glove_vocab.txt')), print_non1=True)\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"/Users/jeong/miniconda3/envs/nlp/lib/python3.10/doctest.py\", line 1350, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest Lab4.getBigramFreqs[1]>\", line 1, in <module>\n",
      "        TestBigramFreqs(getBigramFreqs(preprocess('data/test.txt', mark_ends=True), getVocab('data/glove_vocab.txt')), print_non1=True)\n",
      "      File \"/Users/jeong/Projects/cosc426-projects/cosc426/labs/lab04/Lab4.py\", line 100, in getBigramFreqs\n",
      "        words = line.split()\n",
      "    AttributeError: 'list' object has no attribute 'split'\n",
      "Trying:\n",
      "    len(getVocab('data/glove_vocab.txt'))\n",
      "Expecting:\n",
      "    400003\n",
      "ok\n",
      "Trying:\n",
      "    preprocess('data/test.txt', mark_ends=True)\n",
      "Expecting:\n",
      "    [['[BOS]', 'one', 'thing', 'was', 'certain', ',', 'that', 'the', '_white_', 'kitten', 'had', 'had', 'nothing', 'to', 'do', 'with', 'it', ':', '—it', 'was', 'the', 'black', 'kitten', '’', 's', 'fault', 'entirely', '.', '[EOS]'], ['[BOS]', 'for', 'the', 'white', 'kitten', 'had', 'been', 'having', 'its', 'face', 'washed', 'by', 'the', 'old', 'cat', 'for', 'the', 'last', 'quarter', 'of', 'an', 'hour', '(', 'and', 'bearing', 'it', 'pretty', 'well', ',', 'considering', ')', ';', 'so', 'you', 'see', 'that', 'it', '_couldn', '’', 't_', 'have', 'had', 'any', 'hand', 'in', 'the', 'mischief', '.', '[EOS]']]\n",
      "ok\n",
      "Trying:\n",
      "    preprocess('data/test.txt', mark_ends=False)\n",
      "Expecting:\n",
      "    [['one', 'thing', 'was', 'certain', ',', 'that', 'the', '_white_', 'kitten', 'had', 'had', 'nothing', 'to', 'do', 'with', 'it', ':', '—it', 'was', 'the', 'black', 'kitten', '’', 's', 'fault', 'entirely', '.'], ['for', 'the', 'white', 'kitten', 'had', 'been', 'having', 'its', 'face', 'washed', 'by', 'the', 'old', 'cat', 'for', 'the', 'last', 'quarter', 'of', 'an', 'hour', '(', 'and', 'bearing', 'it', 'pretty', 'well', ',', 'considering', ')', ';', 'so', 'you', 'see', 'that', 'it', '_couldn', '’', 't_', 'have', 'had', 'any', 'hand', 'in', 'the', 'mischief', '.']]\n",
      "ok\n",
      "2 items had no tests:\n",
      "    Lab4\n",
      "    Lab4.TestBigramFreqs\n",
      "2 items passed all tests:\n",
      "   1 tests in Lab4.getVocab\n",
      "   2 tests in Lab4.preprocess\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   2 of   2 in Lab4.getBigramFreqs\n",
      "5 tests in 5 items.\n",
      "3 passed and 2 failed.\n",
      "***Test Failed*** 2 failures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/jeong/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=2, attempted=5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DO NOT CHANGE THIS CHUNK\n",
    "import Lab4\n",
    "import doctest\n",
    "\n",
    "doctest.testmod(Lab4, verbose=True) ## runs the doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618d5ee-276a-4eeb-9d1b-1afaeb6668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct probs to test your implementation of getBigramProb()\n",
    "correct_probs_mle = {\n",
    "        ('one', 'thing'): 1.0,\n",
    "        ('kitten', 'had'): 0.6666666666666666,\n",
    "        ('cat', 'had'): 0.0,\n",
    "        ('had', 'had'): 0.25,\n",
    "        ('on', 'the'): 0.0,\n",
    "        ('held', 'a'): 0.0,\n",
    "        ('zzzzzzz', 'the'): 0.0\n",
    "    }\n",
    "\n",
    "correct_probs_add1 = {\n",
    "        ('one', 'thing'): 4.999950000499995e-06,\n",
    "        ('kitten', 'had'): 7.499887501687475e-06,\n",
    "        ('cat', 'had'): 2.4999750002499977e-06,\n",
    "        ('had', 'had'): 4.999912501531223e-06,\n",
    "        ('on', 'the'): 2.499981250140624e-06,\n",
    "        ('held', 'a'): 2.499981250140624e-06,\n",
    "        ('zzzzzzz', 'the'): 2.4999562507656116e-06\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ce58a-2b2d-4e3a-80fa-d1b54377585b",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "Use this part to answer questions in Part 3. Add as many code and markdown chunks as is helpful. **Remember, once you make changes to your `Lab4.py`, you need to restart the kernel and reimport the file**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f12f1a-e4ba-469a-9e47-22796546569c",
   "metadata": {},
   "source": [
    "## Part 4 (optional)\n",
    "Use this part to answer questions in Part 3. Add as many code and markdown chunks as is helpful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
