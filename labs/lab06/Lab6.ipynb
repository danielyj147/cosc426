{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a26dada8-c3f6-4c7c-8a74-e34854677dc2",
   "metadata": {},
   "source": [
    "# Lab 6: (Sub)Word embeddings\n",
    "### COSC 426: Fall 2025, Colgate University\n",
    "\n",
    "Use this notebook to answer the questions in `Lab6.md`. Make sure to include in this notebook all the tests and experiments you run. Make sure to also cite any external resources you use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e780bc-f9e2-450f-8d9a-e921ffead863",
   "metadata": {},
   "source": [
    "## Part 1: Computing similarity between `GLoVe` embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82844cdc-aafa-4ce4-9343-267921c5bc5c",
   "metadata": {},
   "source": [
    "### Part 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "84f52df1-7548-4ac0-ae62-58c38847b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"glove_dolma_300_10k.pkl\", \"rb\") as f:\n",
    "    glove_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe1ea518-bc91-49ff-8f94-6401a09fd8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(glove_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "539ab3b9-ebfc-4fac-8044-6a350c36a37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"hello\": Dimensions (300,) Mean: -5.767882e-05\n",
      "\"cat\": Dimensions (300,) Mean: -0.00032740872\n",
      "\"chomsky\": Missing embedding\n",
      "\"supercalifragilisticexpialidocious\": Missing embedding\n"
     ]
    }
   ],
   "source": [
    "words = [\"hello\", \"cat\", \"chomsky\", \"supercalifragilisticexpialidocious\"]\n",
    "\n",
    "for word in words:\n",
    "    if word in glove_embeddings:\n",
    "        vec = glove_embeddings[word]\n",
    "        print(f'\"{word}\": Dimensions', vec.shape, \"Mean:\", np.mean(vec))\n",
    "    else:\n",
    "        print(f'\"{word}\": Missing embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53157f-e2db-48f6-af6c-0effe00eaa59",
   "metadata": {},
   "source": [
    "### Part 1.2\n",
    "\n",
    "Implement and test the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69c846dc-f850-4e49-b7dc-efa54f89f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector_glove(word: str, embeddings: dict):\n",
    "    \"\"\"\n",
    "    Return embedding of word if it exists, if not the mean embedding of all words\n",
    "    \"\"\"\n",
    "    if word not in embeddings:\n",
    "        return np.mean(list(embeddings.values()), axis=0)\n",
    "    return embeddings[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fc1d533f-efd2-4a89-bde2-026040dbd58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## Tests\n",
    "print(str(get_word_vector_glove(\"hello\", glove_embeddings).shape) == \"(300,)\")\n",
    "print(str(np.mean(get_word_vector_glove(\"hello\", glove_embeddings))) == \"-5.767882e-05\")\n",
    "print(str(get_word_vector_glove(\"hello\", glove_embeddings)[0]) == \"0.200562\")\n",
    "\n",
    "print(\n",
    "    str(\n",
    "        get_word_vector_glove(\n",
    "            \"supercalifragilisticexpialidocious\", glove_embeddings\n",
    "        ).shape\n",
    "    )\n",
    "    == \"(300,)\"\n",
    ")\n",
    "print(\n",
    "    str(\n",
    "        np.mean(\n",
    "            get_word_vector_glove(\n",
    "                \"supercalifragilisticexpialidocious\", glove_embeddings\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    == \"-0.0065580728\"\n",
    ")\n",
    "print(\n",
    "    str(\n",
    "        get_word_vector_glove(\"supercalifragilisticexpialidocious\", glove_embeddings)[0]\n",
    "    )\n",
    "    == \"-0.08470377\"\n",
    ")\n",
    "\n",
    "print(str(get_word_vector_glove(\"chomsky\", glove_embeddings).shape) == \"(300,)\")\n",
    "print(\n",
    "    str(np.mean(get_word_vector_glove(\"chomsky\", glove_embeddings))) == \"-0.0065580728\"\n",
    ")\n",
    "print(str(get_word_vector_glove(\"chomsky\", glove_embeddings)[0]) == \"-0.08470377\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "084e1ee7-f71e-4e9d-ad07-64d8f17680f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1: np.array, vec2: np.array):\n",
    "    \"\"\"\n",
    "    Returns cosine similarity between two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e04ee40a-8385-42cd-999e-3ae6e4a9b416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    str(cosine_similarity(np.array([1, 2, 3]), np.array([1, 2, -3])))\n",
    "    == \"-0.2857142857142857\"\n",
    ")\n",
    "print(\n",
    "    str(cosine_similarity(np.array([1, 2, 3]), np.array([1, -2, 3])))\n",
    "    == \"0.42857142857142855\"\n",
    ")\n",
    "print(str(cosine_similarity(np.array([1, 2, 3]), np.array([1, 2, 3]))) == \"1.0\")\n",
    "\n",
    "sims = {\n",
    "    \"hello hello\": \"1.0000001\",\n",
    "    \"hello hey\": \"0.93034637\",\n",
    "    \"hello hi\": \"0.9133941\",\n",
    "    \"hello supercalifragilisticexpialidociou\": \"0.73929405\",\n",
    "    \"hello chomsky\": \"0.73929405\",\n",
    "    \"hello cat\": \"0.6564517\",\n",
    "}\n",
    "\n",
    "for key, val in sims.items():\n",
    "    word1, word2 = key.split()\n",
    "    res = str(\n",
    "        cosine_similarity(\n",
    "            get_word_vector_glove(word1, glove_embeddings),\n",
    "            get_word_vector_glove(word2, glove_embeddings),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(res == val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "216052c3-3eca-49d4-a694-098694a7caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(word_vec: np.array, n: int, embeddings: dict, exclude: list):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        word_vec: a word embedding\n",
    "        n: number of similar words to return\n",
    "        embeddings: key word, value embedding\n",
    "        exclude: words to be excluded from the output\n",
    "\n",
    "    Returns:\n",
    "        n words most similar to word; This does not include words in the exclude list\n",
    "    \"\"\"\n",
    "    ecopy = embeddings.copy()\n",
    "    result = {}\n",
    "    for e in exclude:\n",
    "        ecopy.pop(e)\n",
    "\n",
    "    for word, vector in ecopy.items():  # n\n",
    "        result[word] = cosine_similarity(vector, word_vec)  # n\n",
    "    return sorted(result.items(), key=lambda x: x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a8db413-8978-4c1e-ac99-5aa08f5c9507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hey', np.float32(0.9303464)),\n",
       " ('hi', np.float32(0.9133941)),\n",
       " ('thank', np.float32(0.8759045)),\n",
       " ('!', np.float32(0.8671342)),\n",
       " ('thanks', np.float32(0.86197543)),\n",
       " ('dear', np.float32(0.85105634)),\n",
       " ('happy', np.float32(0.8466327)),\n",
       " ('welcome', np.float32(0.8386218)),\n",
       " ('here', np.float32(0.82807004)),\n",
       " ('sorry', np.float32(0.82684636))]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar(\n",
    "    get_word_vector_glove(\"hello\", glove_embeddings),\n",
    "    10,\n",
    "    glove_embeddings,\n",
    "    exclude=[\"hello\"],\n",
    ")\n",
    "\n",
    "## Expected output\n",
    "# [('hello', 1.0000001),\n",
    "#  ('hey', 0.93034637),\n",
    "#  ('hi', 0.9133941),\n",
    "#  ('thank', 0.8759045),\n",
    "#  ('!', 0.8671343),\n",
    "#  ('thanks', 0.86197555),\n",
    "#  ('dear', 0.85105646),\n",
    "#  ('happy', 0.8466327),\n",
    "#  ('welcome', 0.838622),\n",
    "#  ('here', 0.82807016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d028725-3500-4c31-b16b-484685826f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', np.float32(0.9999999)),\n",
       " ('hey', np.float32(0.9303464)),\n",
       " ('hi', np.float32(0.9133941)),\n",
       " ('thank', np.float32(0.8759045)),\n",
       " ('!', np.float32(0.8671342)),\n",
       " ('thanks', np.float32(0.86197543)),\n",
       " ('dear', np.float32(0.85105634)),\n",
       " ('happy', np.float32(0.8466327)),\n",
       " ('welcome', np.float32(0.8386218)),\n",
       " ('here', np.float32(0.82807004))]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar(\n",
    "    get_word_vector_glove(\"hello\", glove_embeddings), 10, glove_embeddings, exclude=[]\n",
    ")\n",
    "\n",
    "## Expected output\n",
    "# [('hello', 1.0000001),\n",
    "#  ('hey', 0.93034637),\n",
    "#  ('hi', 0.9133941),\n",
    "#  ('thank', 0.8759045),\n",
    "#  ('!', 0.8671343),\n",
    "#  ('thanks', 0.86197555),\n",
    "#  ('dear', 0.85105646),\n",
    "#  ('happy', 0.8466327),\n",
    "#  ('welcome', 0.838622),\n",
    "#  ('here', 0.82807016)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a69ee-d299-4ece-8bf1-06a589b56c86",
   "metadata": {},
   "source": [
    "### Part 1.3\n",
    "\n",
    "Answer the following questions: \n",
    "\n",
    "1. What is the time complexity of `find_similar` if your vocab has `v` words, your embedding size is `m`, and you want to find `n` most similar words to the inputted word? \n",
    "\n",
    "we cannot assume cos sim is \n",
    "\n",
    "cosine_similarity is o(m) due to the dot product operation which requires multiplying m\n",
    "columns, and this function is run v times to get the similarities for all words in find_similarity. As a result, find_similarity is o(m*v + v*log(v)) since sorting is vlog(v). n is not important because it just involves taking the top n elements of the sorted array.\n",
    "\n",
    "\n",
    "1. Consider a scenario (e.g., web application that displays similar words) where you might have to repeatedly run `find_similar`, say for `x` times. What are the benefits and challenges of pre-computing the similarity between all words? How might you overcome the challenges? \n",
    "\n",
    "It is beneficial becuase saving the pre-computed vlaue eliminates the need to calculate the similiarities so the time complexirty of finding similar words become constant. However, it might waste computing power because the initial operation is o(v(m*v + v*log(v))), and it may not be necessary to compute the similarities for all words, as some less frequent words may not be used. Instead, the similarities could be only computed for the most common words. The storage would also be v^2, and in order to reduce that, only the first 100 most similar words could be stored for each word. It is unlikely to need any more than about the first 100 most similar words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782c9c8-d795-4bae-bf84-3aa3de09509e",
   "metadata": {},
   "source": [
    "## Part 2: Computing similarity between `distilgpt` embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb03d1f-8117-4b8f-8e09-da0eff9bd6a1",
   "metadata": {},
   "source": [
    "### Part 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "361e9379-90da-4c04-b4a2-ef1cf7e066c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"distilgpt2\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "embedding_matrix = model.get_input_embeddings().weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fba6934f-5cca-4d3e-91ae-1108076e2152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello']\n",
      "[31373]\n",
      "hello torch.Size([1, 768])\n",
      "['cat']\n",
      "[9246]\n",
      "cat torch.Size([1, 768])\n",
      "['ch', 'omsky']\n",
      "[354, 37093]\n",
      "chomsky torch.Size([2, 768])\n",
      "['super', 'cal', 'if', 'rag', 'il', 'ist', 'ice', 'xp', 'ial', 'id', 'ocious']\n",
      "[16668, 9948, 361, 22562, 346, 396, 501, 42372, 498, 312, 32346]\n",
      "supercalifragilisticexpialidocious torch.Size([11, 768])\n"
     ]
    }
   ],
   "source": [
    "words = [\"hello\", \"cat\", \"chomsky\", \"supercalifragilisticexpialidocious\"]\n",
    "\n",
    "for word in words:\n",
    "    tokens = tokenizer.tokenize(word, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    print(tokens)\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    print(ids)\n",
    "    embeds = embedding_matrix[ids]\n",
    "    print(word, embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa00ac-9096-474c-b5b1-db1ae8363505",
   "metadata": {},
   "source": [
    "#### Answer the following question\n",
    "How does `distilgpt` handle words that are not in its vocab? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ac9fe-27de-48e7-a906-fd6ffe9d0693",
   "metadata": {},
   "source": [
    "It divides the word into sub-word tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b62ca4-a338-4cb6-880c-adb0b284f3ee",
   "metadata": {},
   "source": [
    "### Part 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a54c0e2b-307a-4fb9-a502-284a000b921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hf_wordvec(word, tokenizer, embedding_matrix):\n",
    "    \"\"\"\n",
    "    Returns an embedding that is the average over all the sub-word tokens\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(word, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    d = {}\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    i = 0\n",
    "    for id in ids:\n",
    "        d[tokens[i]] = embedding_matrix[id].detach().numpy()\n",
    "        i += 1\n",
    "    return np.mean(list(d.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6cc74336-c010-449f-8d16-1b9b32bbf8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(str(get_hf_wordvec(\"hello\", tokenizer, embedding_matrix).shape) == \"(768,)\")\n",
    "print(\n",
    "    str(np.mean(get_hf_wordvec(\"hello\", tokenizer, embedding_matrix)))\n",
    "    == \"-0.0013018699\"\n",
    ")\n",
    "print(str(get_hf_wordvec(\"hello\", tokenizer, embedding_matrix)[0]) == \"-0.029814368\")\n",
    "\n",
    "print(\n",
    "    str(\n",
    "        get_hf_wordvec(\n",
    "            \"supercalifragilisticexpialidocious\", tokenizer, embedding_matrix\n",
    "        ).shape\n",
    "    )\n",
    "    == \"(768,)\"\n",
    ")\n",
    "print(\n",
    "    str(\n",
    "        np.mean(\n",
    "            get_hf_wordvec(\n",
    "                \"supercalifragilisticexpialidocious\", tokenizer, embedding_matrix\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    == \"-0.0007369095\"\n",
    ")\n",
    "print(\n",
    "    str(\n",
    "        get_hf_wordvec(\n",
    "            \"supercalifragilisticexpialidocious\", tokenizer, embedding_matrix\n",
    "        )[0]\n",
    "    )\n",
    "    == \"-0.023058223\"\n",
    ")\n",
    "\n",
    "print(str(get_hf_wordvec(\"chomsky\", tokenizer, embedding_matrix).shape) == \"(768,)\")\n",
    "print(\n",
    "    str(np.mean(get_hf_wordvec(\"chomsky\", tokenizer, embedding_matrix)))\n",
    "    == \"0.0015589814\"\n",
    ")\n",
    "print(str(get_hf_wordvec(\"chomsky\", tokenizer, embedding_matrix)[0]) == \"0.026135625\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d44943-5bc4-4b13-80c5-dd8e1526f54f",
   "metadata": {},
   "source": [
    "### Part 2.3\n",
    "\n",
    "What are the limitations of using `embedding_matrix` in `find_similar`? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f1972-daa9-47e9-9e17-fefa76fea61c",
   "metadata": {},
   "source": [
    "Since embedding_matrix also considers subwords, it will return smiliar subwords rather than complete words. It would likely return the subwords within the word as the first few most similar results, which is not necessarily useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d20495-ba9c-41fe-a099-903930c021b2",
   "metadata": {},
   "source": [
    "### Part 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc192b80-93df-44bc-8a0c-31c601954f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def create_hf_embeddings(hf_model_name: str, vocab: set):\n",
    "    \"\"\"\n",
    "    Returns dictionary. Key: words in the vocab; Value: word embeddings for the hf_model for the word\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = hf_model_name\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    embedding_matrix = model.get_input_embeddings().weight\n",
    "\n",
    "    d = {}\n",
    "    for word in vocab:\n",
    "        d[word] = get_hf_wordvec(word, tokenizer, embedding_matrix)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "790eaddc-7502-4706-9872-54cca532823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "gpt_embeddings = create_hf_embeddings(model_name, glove_embeddings.keys())\n",
    "print(len(glove_embeddings.keys()))\n",
    "print(len(gpt_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13caf34d-42c1-4786-b8b2-116827dbfcc9",
   "metadata": {},
   "source": [
    "## Part 3: Using analogies to study encoding of gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cabf86-34f3-4a1d-9242-2207de15727c",
   "metadata": {},
   "source": [
    "### Part 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "97add024-89d9-4479-959c-600c20bf506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_analogy(analogy: str, embeddings: dict, n: int):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        analogy: String of the format: a - b + c\n",
    "        embeddings:  key word, value embedding\n",
    "        n: number of cloest words to return\n",
    "    Returns:\n",
    "        n cloest words to the resulting analogy embedding\n",
    "    \"\"\"\n",
    "\n",
    "    words = analogy.split()\n",
    "\n",
    "    a = words[0]\n",
    "    b = words[2]\n",
    "    c = words[-1]\n",
    "\n",
    "    av = get_word_vector_glove(a, embeddings)\n",
    "    bv = get_word_vector_glove(b, embeddings)\n",
    "    cv = get_word_vector_glove(c, embeddings)\n",
    "\n",
    "    d = av - bv + cv\n",
    "\n",
    "    r = find_similar(d, n, embeddings, [a, b, c])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c2f05-2ae7-4658-9888-7dc61f9582c1",
   "metadata": {},
   "source": [
    "### Part 3.2\n",
    "Come up with at least 10 analogies that you think are important for testing how robustly gender is encoded in some embeddings. Justify why you picked the examples you did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "807c32f9-142e-4923-89a5-f164bfda5e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actress - woman + man\n",
      "[('congressman', np.float32(0.5581259)), ('act', np.float32(0.50505763)), ('mattress', np.float32(0.4937233)), ('intact', np.float32(0.46369284)), ('compact', np.float32(0.46041718))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "actor - man + woman\n",
      "[('act', np.float32(0.47990918)), ('acting', np.float32(0.46729234)), ('actress', np.float32(0.46015057)), ('female', np.float32(0.44012728)), ('interact', np.float32(0.4395723))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "grandfather - man + woman\n",
      "[('grandmother', np.float32(0.72981995)), ('grandparents', np.float32(0.6882695)), ('grandchildren', np.float32(0.6657016)), ('grand', np.float32(0.6172141)), ('mother', np.float32(0.60765404))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "grandmother - woman + man\n",
      "[('grandfather', np.float32(0.63001597)), ('grand', np.float32(0.5878212)), ('grandparents', np.float32(0.56019825)), ('grandma', np.float32(0.55384135)), ('goodman', np.float32(0.5329792))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "husband - man + woman\n",
      "[('wife', np.float32(0.6080911)), ('girlfriend', np.float32(0.58680815)), ('daughter', np.float32(0.56152576)), ('female', np.float32(0.52158856)), ('marriage', np.float32(0.51474506))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wife - woman + man\n",
      "[('wives', np.float32(0.5124007)), ('freshman', np.float32(0.5092985)), ('goodman', np.float32(0.49525028)), ('chairman', np.float32(0.48415917)), ('newman', np.float32(0.47917813))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "daughter - woman + man\n",
      "[('freshman', np.float32(0.51971245)), ('son', np.float32(0.5103639)), ('johnson', np.float32(0.5084293)), ('father', np.float32(0.49662414)), ('goldman', np.float32(0.4951986))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "son - man + women\n",
      "[('johnson', np.float32(0.6239957)), ('jackson', np.float32(0.59371907)), ('tyson', np.float32(0.5657403)), ('sony', np.float32(0.55995446)), ('daughter', np.float32(0.5562989))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "doctor - woman + man\n",
      "[('goodman', np.float32(0.5281397)), ('freshman', np.float32(0.4957739)), ('businessman', np.float32(0.4825576)), ('friedman', np.float32(0.47329122)), ('goldman', np.float32(0.47089487))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "doctor - man + woman\n",
      "[('women', np.float32(0.51624435)), ('girlfriend', np.float32(0.5122506)), ('abortion', np.float32(0.5119078)), ('female', np.float32(0.51094514)), ('psychologist', np.float32(0.50233066))]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "alist = [\n",
    "    \"actress - woman + man\",\n",
    "    \"actor - man + woman\",\n",
    "    \"grandfather - man + woman\",\n",
    "    \"grandmother - woman + man\",\n",
    "    \"husband - man + woman\",\n",
    "    \"wife - woman + man\",\n",
    "    \"daughter - woman + man\",\n",
    "    \"son - man + women\",\n",
    "    \"doctor - woman + man\",\n",
    "    \"doctor - man + woman\",\n",
    "]\n",
    "\n",
    "n = 5\n",
    "\n",
    "for a in alist:\n",
    "    print(a)\n",
    "    print(compute_analogy(a, gpt_embeddings, n))\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c5c5c",
   "metadata": {},
   "source": [
    "These examples compare how the model predicts gender both ways by using minimal pairs like actress and actor or aunt uncle. By subtracting man and woman, we can ensure it doesn't just prefer one gender and gender is accurately encoded in the embeddings. We also used some non-family examples such as doctor and actor / actress. Additionally, doctor was a gender neutral example to test whether the model has gender bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3772284c-8897-4bb5-8e1b-597264dab598",
   "metadata": {},
   "source": [
    "### Part 3.3\n",
    "Using analogies from the previous part, test how robustly gender is encoded in `GLoVe` and `distilgpt` embeddings. Add as many code and markdown chunks as you would like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a9d79-dbc0-4c84-b69b-aed3c1e7bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actress - woman + man\n",
      "[('actor', np.float32(0.90144706)), ('starring', np.float32(0.90102714)), ('star', np.float32(0.8071807)), ('stars', np.float32(0.79611397)), ('movie', np.float32(0.7727861))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "actor - man + woman\n",
      "[('actress', np.float32(0.9177098)), ('actors', np.float32(0.79851186)), ('starring', np.float32(0.78691894)), ('celebrity', np.float32(0.73182064)), ('portrayed', np.float32(0.7258368))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "grandfather - man + woman\n",
      "[('grandmother', np.float32(0.90214145)), ('mother', np.float32(0.8688457)), ('daughter', np.float32(0.8610478)), ('wife', np.float32(0.84839374)), ('sister', np.float32(0.8347685))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "grandmother - woman + man\n",
      "[('grandfather', np.float32(0.88643765)), ('uncle', np.float32(0.8650666)), ('father', np.float32(0.84343225)), ('dad', np.float32(0.83388627)), ('grandma', np.float32(0.83195907))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "husband - man + woman\n",
      "[('wife', np.float32(0.9121501)), ('daughter', np.float32(0.8868473)), ('mother', np.float32(0.87561476)), ('sister', np.float32(0.8712925)), ('married', np.float32(0.8619271))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wife - woman + man\n",
      "[('brother', np.float32(0.91131103)), ('father', np.float32(0.8935649)), ('uncle', np.float32(0.8793853)), ('husband', np.float32(0.873704)), ('friend', np.float32(0.86958253))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "daughter - woman + man\n",
      "[('brother', np.float32(0.91893035)), ('father', np.float32(0.9042075)), ('son', np.float32(0.8937602)), ('uncle', np.float32(0.8811955)), ('cousin', np.float32(0.8519015))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "son - man + women\n",
      "[('daughters', np.float32(0.8288464)), ('children', np.float32(0.79413193)), ('daughter', np.float32(0.7876921)), ('mothers', np.float32(0.78724426)), ('parents', np.float32(0.7794989))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "doctor - woman + man\n",
      "[('doctors', np.float32(0.75633633)), ('he', np.float32(0.7436806)), ('physician', np.float32(0.7328898)), ('medication', np.float32(0.7310419)), ('gave', np.float32(0.7310066))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "doctor - man + woman\n",
      "[('doctors', np.float32(0.80853134)), ('nurse', np.float32(0.8022091)), ('physician', np.float32(0.790518)), ('pregnant', np.float32(0.789272)), ('she', np.float32(0.7868319))]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for a in alist:\n",
    "    print(a)\n",
    "    print(compute_analogy(a, glove_embeddings, n))\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250dad27",
   "metadata": {},
   "source": [
    "Gender is robustly encoded in both models, and both only would output correctly gendered words when subtracting man or woman. However, glove was significantly more accurate in predicting the expected term in the top 10 output, while distilgpt rarely output the expected term and instead output similarly gendered terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4869d-be8a-4957-b412-cc56df3872e8",
   "metadata": {},
   "source": [
    "## Part 4 (optional): Using analogies to study encoding of other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8da9ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blist = [\n",
    "    \"runs - run + eat\",\n",
    "    \"flies - fly + walk\",\n",
    "    \"goes - go + walk\",\n",
    "    \"does - do + say\",\n",
    "    \"has - have + need\",\n",
    "    \"plays - play + work\",\n",
    "    \"writes - write + read\",\n",
    "    \"sings - sing + ride\",\n",
    "    \"moves - move + jump\",\n",
    "    \"comes - come + leave\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae06729",
   "metadata": {},
   "source": [
    "Justify why you think this is a useful feature:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7c619f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs - run + eat\n",
      "[('defeat', np.float32(0.68148243)), ('eaten', np.float32(0.6510309)), ('eating', np.float32(0.554748)), ('breaks', np.float32(0.40725547)), ('carbohydrates', np.float32(0.39687207))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "flies - fly + walk\n",
      "[('walked', np.float32(0.6367054)), ('walking', np.float32(0.57056844)), ('walnuts', np.float32(0.50213677)), ('walker', np.float32(0.47031176)), ('walks', np.float32(0.46179622))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "goes - go + walk\n",
      "[('walked', np.float32(0.7552455)), ('walking', np.float32(0.57059413)), ('walker', np.float32(0.51984304)), ('crosses', np.float32(0.50737846)), ('writes', np.float32(0.5015175))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "does - do + say\n",
      "[('said', np.float32(0.47283748)), ('would', np.float32(0.4654507)), ('makes', np.float32(0.4511572)), ('perhaps', np.float32(0.44185963)), ('could', np.float32(0.4372527))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "has - have + need\n",
      "[('needle', np.float32(0.6150822)), ('needles', np.float32(0.61257786)), ('needs', np.float32(0.5438574)), ('should', np.float32(0.4246652)), ('requires', np.float32(0.42334992))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "plays - play + work\n",
      "[('workouts', np.float32(0.6548067)), ('workout', np.float32(0.61307096)), ('workforce', np.float32(0.61147904)), ('workplace', np.float32(0.6078713)), ('artwork', np.float32(0.59683))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "writes - write + read\n",
      "[('readers', np.float32(0.60867393)), ('readings', np.float32(0.54401165)), ('readily', np.float32(0.5268236)), ('processes', np.float32(0.51142496)), ('sees', np.float32(0.49713412))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sings - sing + ride\n",
      "[('ratings', np.float32(0.45576203)), ('meetings', np.float32(0.43746147)), ('brings', np.float32(0.43487433)), ('offerings', np.float32(0.42998877)), ('feelings', np.float32(0.42693692))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "moves - move + jump\n",
      "[('moved', np.float32(0.45724082)), ('majors', np.float32(0.45121017)), ('loves', np.float32(0.45062718)), ('movies', np.float32(0.45044187)), ('mushrooms', np.float32(0.44204113))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "comes - come + leave\n",
      "[('outcomes', np.float32(0.47817978)), ('incomes', np.float32(0.4715343)), ('remove', np.float32(0.43690434)), ('does', np.float32(0.4122741)), ('makes', np.float32(0.41033983))]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for a in blist:\n",
    "    print(a)\n",
    "    print(compute_analogy(a, gpt_embeddings, n))\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b6e5d563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs - run + eat\n",
      "[('eating', np.float32(0.9161597)), ('eats', np.float32(0.8856606)), ('eaten', np.float32(0.8730644)), ('ate', np.float32(0.86588645)), ('meal', np.float32(0.84295464))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "flies - fly + walk\n",
      "[('walking', np.float32(0.8480631)), ('walks', np.float32(0.8360235)), ('walked', np.float32(0.7872538)), ('beside', np.float32(0.7817013)), ('away', np.float32(0.77839863))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "goes - go + walk\n",
      "[('walking', np.float32(0.89258105)), ('walks', np.float32(0.88117766)), ('sits', np.float32(0.85227436)), ('close', np.float32(0.83825624)), ('turns', np.float32(0.83417255))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "does - do + say\n",
      "[(\"'s\", np.float32(0.9365444)), ('seems', np.float32(0.932347)), ('fact', np.float32(0.91629213)), ('why', np.float32(0.91581726)), ('saying', np.float32(0.91524094))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "has - have + need\n",
      "[('needs', np.float32(0.956717)), ('will', np.float32(0.9467876)), ('is', np.float32(0.9426233)), ('for', np.float32(0.9331508)), ('to', np.float32(0.92569226))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "plays - play + work\n",
      "[('works', np.float32(0.8627097)), ('working', np.float32(0.851017)), ('and', np.float32(0.8449116)), ('worked', np.float32(0.8442472)), ('also', np.float32(0.837421))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "writes - write + read\n",
      "[('author', np.float32(0.87094027)), ('explains', np.float32(0.8394157)), ('wrote', np.float32(0.8317161)), ('describes', np.float32(0.8149364)), ('book', np.float32(0.8093536))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sings - sing + ride\n",
      "[('rides', np.float32(0.84905547)), ('riding', np.float32(0.82073593)), ('bike', np.float32(0.76828206)), ('rider', np.float32(0.74190974)), ('driving', np.float32(0.72891134))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "moves - move + jump\n",
      "[('jumps', np.float32(0.91040415)), ('jumping', np.float32(0.8395818)), ('hits', np.float32(0.7686834)), ('hit', np.float32(0.75663555)), ('throws', np.float32(0.75413287))]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "comes - come + leave\n",
      "[('goes', np.float32(0.9040558)), ('takes', np.float32(0.89228314)), ('leaving', np.float32(0.8909155)), ('does', np.float32(0.88872474)), ('is', np.float32(0.8864569))]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for a in blist:\n",
    "    print(a)\n",
    "    print(compute_analogy(a, glove_embeddings, n))\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f16a8",
   "metadata": {},
   "source": [
    "Plurality is a useful feature to test because it is essential for language models to understand plurality in order to generate text, and this is a simple way to test whether the embeddings can capture plurality.\n",
    "\n",
    "The feature of plurality was definitely encoded in both distilgpt and glove, but it often output words that were similar in meaning to the verbs rather than solely the plural version. Glove was also far more effective, and it accurately predicted the singular version for jump, ride, work, and need as the most likely prediction.\n",
    "\n",
    "How useful do you think similarity or analogies are in evaluating word embeddings? Are there any limits on the kind of features you can probe?\n",
    "Analogies are a relatively simple way to evaluate words and often output words outside the scope of the experiment that are generally similar in usage or meaning. This type of experiment also requires that there be a binary difference between words so the meanings can be easily subtracted. Each word needs a specific inverse which exactly captures the difference, which may not always be the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c2860",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
